# Ch02 카프카 빠르게 시작하기

## 브로커 실행 

### 카프카 브로커 힙 메모리 설정

- 레코드는 페이지 캐시로 시스템 메모리를 사용한 후에 나머지 객체들을 힙 메모리에 저장
- 보통 5GB 메모리 이상으로 설정하지 않음
- 기본 설정은 카프카 브로커는 1G, 주키퍼는 512MB
- `KAFKA_HEAP_OPTS=-Xmx1G -Xms1G`


**`kafka-server-start.sh`**의 내용

```
...

if [ "x$KAFKA_LOG4J_OPTS" = "x" ]; then
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j.properties"
fi

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
fi

EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc'}

COMMAND=$1
case $COMMAND in
  -daemon)
    EXTRA_ARGS="-daemon "$EXTRA_ARGS
    shift
    ;;
  *)
    ;;
esac

exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```

### 카프카 브로커 실행 옵션 설정 

보다 자세한 문서: http://kafka.apache.org/documentation.html#brokerconfigs

- broker.id=1 브로커를 구분하기 위한 ID
- listners: 카프카 브로커 소켓이 내부적으로 바인딩하는 주소 (ex. PLAINTEXT://:9092)
- advertiesed.listeners: 카프카 클라이언트, 즉, 카프카 프로듀서, 컨슈머가 사용하는 주소 (ex. PLAINTEXT://kafka-1.kafka-headless:9092)
- num.network.threads=3 네트워크용 쓰레드 개수
- num.io.threads=8 DISK I/O를 포함, 요청을 처리하기 위한 쓰레드 개수 
- log.dirs=/kafka/kafka-logs 로그 디렉토리
- num.partitions=1 토픽별 기본 로그 파티션의 수, 파티션이 많아질수록 병렬처리가 좋지만, 브로커 간의 파일 개수도 늘어남
- log.segment.bytes 싱글 로그 파일의 최대 크기 (기본값 1G)
- log.roll.{ms,hours} 다음 세그먼트를 생성하기까지의 시간
- log.cleanup.policy 리텐선 윈도우 이후의 로그 세그먼트 삭제 정책 (기본값은 delete, compact)
- log.retention.{ms,minutes,hours}=168 로그 세그먼트를 저장하는 시간. 
- log.retention.bytes=1073741824
- log.retention.check.interval.ms=300000
- log.cleaner.enable
- log.cleaner.threads
- log.cleaner.backoff.ms
- log.index.size.max.bytes
- log.index.interval.byte
- log.flush.interval.messags
- log.flush.interval.ms
- zookeeper.connect=zookeeper-0.zookeeper-headless:2181,zookeeper-1.zookeeper-headless:2181,zookeeper-2.zookeeper-headless:2181/kafka
- zookeeper.connection.timeout.ms=18000

### Pod에서 설정되는 환경변수들

```
 env:
        - name: BROKER_ID_COMMAND
          value: '[[ `hostname` =~ -([0-9]+) ]] && echo ${BASH_REMATCH[1]}'
        - name: HOSTNAME_COMMAND
          value: hostname
        - name: KAFKA_LISTENERS
          value: 'PLAINTEXT://:9092'
        - name: KAFKA_ADVERTISED_LISTENERS
          value: 'PLAINTEXT://_{HOSTNAME_COMMAND}.kafka-headless:9092'
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: >-
            zookeeper-0.zookeeper-headless:2181,zookeeper-1.zookeeper-headless:2181,zookeeper-2.zookeeper-headless:2181/kafka
        - name: KAFKA_LOG_DIRS
          value: /kafka/kafka-logs
        - name: KAFKA_JMX_PORT
          value: '5555'
        - name: KAFKA_CLEANUP_POLICY
          value: compact
```

### 도커 파일

- [start-kafka.sh](https://github.com/wurstmeister/kafka-docker/blob/master/start-kafka.sh)  도커 파일의 엔트리 포인트 

```
....
  # Fixes #312
    # KAFKA_VERSION + KAFKA_HOME + grep -rohe KAFKA[A-Z0-0_]* /opt/kafka/bin | sort | uniq | tr '\n' '|'
    EXCLUSIONS="|KAFKA_VERSION|KAFKA_HOME|KAFKA_DEBUG|KAFKA_GC_LOG_OPTS|KAFKA_HEAP_OPTS|KAFKA_JMX_OPTS|KAFKA_JVM_PERFORMANCE_OPTS|KAFKA_LOG|KAFKA_OPTS|"

    # Read in env as a new-line separated array. This handles the case of env variables have spaces and/or carriage returns. See #313
    IFS=$'\n'
    for VAR in $(env)
    do
        env_var=$(echo "$VAR" | cut -d= -f1)
        if [[ "$EXCLUSIONS" = *"|$env_var|"* ]]; then
            echo "Excluding $env_var from broker config"
            continue
        fi

        if [[ $env_var =~ ^KAFKA_ ]]; then
            kafka_name=$(echo "$env_var" | cut -d_ -f2- | tr '[:upper:]' '[:lower:]' | tr _ .)
            updateConfig "$kafka_name" "${!env_var}" "$KAFKA_HOME/config/server.properties"
        fi

        if [[ $env_var =~ ^LOG4J_ ]]; then
            log4j_name=$(echo "$env_var" | tr '[:upper:]' '[:lower:]' | tr _ .)
            updateConfig "$log4j_name" "${!env_var}" "$KAFKA_HOME/config/log4j.properties"
        fi
    done
...
exec "$KAFKA_HOME/bin/kafka-server-start.sh" "$KAFKA_HOME/config/server.properties"
```

## 브로커 통신 확인

```
bash-4.4# bin/kafka-broker-api-versions.sh --bootstrap-server kafka-1.kafka-headless:9092
kafka-1.kafka-headless:9092 (id: 1 rack: null) -> (
        Produce(0): 0 to 8 [usable: 8],
        Fetch(1): 0 to 12 [usable: 12],
        ListOffsets(2): 0 to 5 [usable: 5],
        Metadata(3): 0 to 9 [usable: 9],
        LeaderAndIsr(4): 0 to 4 [usable: 4],
        StopReplica(5): 0 to 3 [usable: 3],
        UpdateMetadata(6): 0 to 6 [usable: 6],
        ControlledShutdown(7): 0 to 3 [usable: 3],
        OffsetCommit(8): 0 to 8 [usable: 8],
        OffsetFetch(9): 0 to 7 [usable: 7],
        FindCoordinator(10): 0 to 3 [usable: 3],
        JoinGroup(11): 0 to 7 [usable: 7],
        Heartbeat(12): 0 to 4 [usable: 4],
        LeaveGroup(13): 0 to 4 [usable: 4],
        SyncGroup(14): 0 to 5 [usable: 5],
        DescribeGroups(15): 0 to 5 [usable: 5],
        ListGroups(16): 0 to 4 [usable: 4],
        SaslHandshake(17): 0 to 1 [usable: 1],
        ApiVersions(18): 0 to 3 [usable: 3],
        CreateTopics(19): 0 to 6 [usable: 6],
        DeleteTopics(20): 0 to 5 [usable: 5],
        DeleteRecords(21): 0 to 2 [usable: 2],
        InitProducerId(22): 0 to 4 [usable: 4],
        OffsetForLeaderEpoch(23): 0 to 3 [usable: 3],
        AddPartitionsToTxn(24): 0 to 2 [usable: 2],
        AddOffsetsToTxn(25): 0 to 2 [usable: 2],
        EndTxn(26): 0 to 2 [usable: 2],
        WriteTxnMarkers(27): 0 [usable: 0],
        TxnOffsetCommit(28): 0 to 3 [usable: 3],
        DescribeAcls(29): 0 to 2 [usable: 2],
        CreateAcls(30): 0 to 2 [usable: 2],
        DeleteAcls(31): 0 to 2 [usable: 2],
        DescribeConfigs(32): 0 to 3 [usable: 3],
        AlterConfigs(33): 0 to 1 [usable: 1],
        AlterReplicaLogDirs(34): 0 to 1 [usable: 1],
        DescribeLogDirs(35): 0 to 2 [usable: 2],
        SaslAuthenticate(36): 0 to 2 [usable: 2],
        CreatePartitions(37): 0 to 3 [usable: 3],
        CreateDelegationToken(38): 0 to 2 [usable: 2],
        RenewDelegationToken(39): 0 to 2 [usable: 2],
        ExpireDelegationToken(40): 0 to 2 [usable: 2],
        DescribeDelegationToken(41): 0 to 2 [usable: 2],
        DeleteGroups(42): 0 to 2 [usable: 2],
        ElectLeaders(43): 0 to 2 [usable: 2],
        IncrementalAlterConfigs(44): 0 to 1 [usable: 1],
        AlterPartitionReassignments(45): 0 [usable: 0],
        ListPartitionReassignments(46): 0 [usable: 0],
        OffsetDelete(47): 0 [usable: 0],
        DescribeClientQuotas(48): 0 [usable: 0],
        AlterClientQuotas(49): 0 [usable: 0],
        DescribeUserScramCredentials(50): 0 [usable: 0],
        AlterUserScramCredentials(51): 0 [usable: 0],
        AlterIsr(56): 0 [usable: 0],
        UpdateFeatures(57): 0 [usable: 0]
)
...
```

### 토픽 생성

브로커 리스트 

```
$  k exec -it kafkacat -- kafkacat -b kafka-headless:9092 -L
Metadata for all topics (from broker -1: kafka-headless:9092/bootstrap):
 4 brokers:
  broker 0 at kafka-0.kafka-headless:9092
  broker 2 at kafka-2.kafka-headless:9092 (controller)
  broker 3 at kafka-3.kafka-headless:9092
  broker 1 at kafka-1.kafka-headless:9092
 1 topics:
  topic "hello.kafka" with 1 partitions:
    partition 0, leader 1, replicas: 1, isrs: 1
```

kafka-client를 이용

```
$  k exec -it kafka-client -- \
	kafka-topics.sh --create \
	--bootstrap-server kafka-headless:9092 \
	--topic hello.kafka2 \
	--partitions 3 \
	--replication-factor 1 \
	--config retention.ms=172800000
```
